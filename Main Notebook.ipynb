{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457094b7",
   "metadata": {},
   "source": [
    "# Classification and Distribution of M-Type Asteroids\n",
    "## Introduction to Data Science (MATH 4100/COMP 5360) Final Project\n",
    "## Matt Storie and Ian Wixom\n",
    "---\n",
    "## Part 0: Setup and Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c147b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and Setup\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6) \n",
    "\n",
    "#Custom Functions for use later\n",
    "#Increases print output for one printing\n",
    "def print_all(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "322184f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports are large so I am keeping them in their own cell for now\n",
    "astro1 = pd.read_csv('C:/Users/matts/ds/Classification-and-Analysis-of-M-type-Asteroids/split_astro_ds_1.csv', low_memory = False)\n",
    "astro2 = pd.read_csv('C:/Users/matts/ds/Classification-and-Analysis-of-M-type-Asteroids/split_astro_ds_2.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58e7bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame Formatting\n",
    "# The Second file did not have all of the same columns, so we are adding them now\n",
    "# and filling missing values with NA\n",
    "astro2.columns = ['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'n_obs_used', 'H',\n",
    "       'diameter', 'extent', 'albedo', 'rot_per']\n",
    "astro2['GM'] = np.nan\n",
    "astro2['BV'] = np.nan\n",
    "astro2['UB'] = np.nan\n",
    "astro2['IR'] = np.nan\n",
    "astro2['spec_B'] = np.nan\n",
    "astro2['spec_T'] = np.nan\n",
    "astro = pd.concat([astro1, astro2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a07ca",
   "metadata": {},
   "source": [
    "## Part 1 Classification of Unclassified Asteroids\n",
    "Before we can explore the full set, we are going to need to train a model to classify the unclassified asteroids of the set before exploring the full set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c4c50bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1048573 total observed objects in the dataset\n",
      "1742 have been classified, while 1046831 remain unclassified.\n",
      "---\n",
      "SMASS Value Counts\n",
      "S      348\n",
      "C      139\n",
      "Ch     135\n",
      "X      112\n",
      "Xc      59\n",
      "B       56\n",
      "Sl      47\n",
      "Sq      44\n",
      "Xk      39\n",
      "V       35\n",
      "L       33\n",
      "K       31\n",
      "Cb      30\n",
      "Sa      29\n",
      "Xe      24\n",
      "Cgh     15\n",
      "T       13\n",
      "Sk      12\n",
      "A       12\n",
      "Ld      11\n",
      "Sr      11\n",
      "Cg       9\n",
      "D        8\n",
      "R        4\n",
      "O        1\n",
      "U        1\n",
      "Name: spec_B, dtype: int64\n",
      "---\n",
      "Tholen Value Counts\n",
      "S         311\n",
      "C         137\n",
      "X          51\n",
      "M          37\n",
      "D          33\n",
      "P          33\n",
      "F          27\n",
      "XC         22\n",
      "CX         21\n",
      "C:         10\n",
      "E          10\n",
      "CP         10\n",
      "G           9\n",
      "B           8\n",
      "FC          7\n",
      "SU          7\n",
      "PC          6\n",
      "T           6\n",
      "CU          5\n",
      "CX:         5\n",
      "A           5\n",
      "ST          5\n",
      "XFU         5\n",
      "DU          4\n",
      "CSU         4\n",
      "FXU:        4\n",
      "CG          4\n",
      "CF          4\n",
      "CPF         3\n",
      "DX          3\n",
      "BU          3\n",
      "MU          3\n",
      "GC          3\n",
      "DP          3\n",
      "XD          3\n",
      "CD          3\n",
      "I           3\n",
      "XDC         2\n",
      "XCU         2\n",
      "XD:         2\n",
      "PD          2\n",
      "XF          2\n",
      "FCX         2\n",
      "XB          2\n",
      "CB          2\n",
      "DTU:        2\n",
      "TD          2\n",
      "DT          2\n",
      "DU:         2\n",
      "CD:         2\n",
      "BCU         2\n",
      "CXF         2\n",
      "SR          2\n",
      "TDG         2\n",
      "SCTU        2\n",
      "DCX:        2\n",
      "DCX         2\n",
      "BFC         1\n",
      "BC:         1\n",
      "PDC         1\n",
      "MU:         1\n",
      "FCU         1\n",
      "CGTP:       1\n",
      "XFC         1\n",
      "P:          1\n",
      "XSC         1\n",
      "CFU:        1\n",
      "PF          1\n",
      "FU          1\n",
      "FC:         1\n",
      "CB:         1\n",
      "XU          1\n",
      "AS          1\n",
      "PU          1\n",
      "XSCU        1\n",
      "STU         1\n",
      "G:          1\n",
      "CBU         1\n",
      "FBCU::      1\n",
      "XFCU        1\n",
      "BU:         1\n",
      "DSU:        1\n",
      "CFXU        1\n",
      "SG          1\n",
      "BCU:        1\n",
      "SDU::       1\n",
      "BFX         1\n",
      "DTU         1\n",
      "GS:         1\n",
      "FCB         1\n",
      "XB:         1\n",
      "R           1\n",
      "CSGU        1\n",
      "F:          1\n",
      "X:          1\n",
      "FP          1\n",
      "BFU::       1\n",
      "CGU         1\n",
      "CDX:        1\n",
      "CFB:        1\n",
      "XC:         1\n",
      "PCD         1\n",
      "TSD         1\n",
      "FCX:        1\n",
      "SD          1\n",
      "CTGU:       1\n",
      "GU          1\n",
      "CP:         1\n",
      "DX:         1\n",
      "STGD        1\n",
      "CGSU        1\n",
      "FX:         1\n",
      "SC          1\n",
      "CPU:        1\n",
      "GC:         1\n",
      "DXCU        1\n",
      "V           1\n",
      "QSV         1\n",
      "CBU:        1\n",
      "TS          1\n",
      "Name: spec_T, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now that the frames are combined we can perform exploratory analysis\n",
    "# print(astro.head())\n",
    "\n",
    "# Examining the number of unclassified asteroids of the dataset\n",
    "tot_unclassified = len(astro[(astro['spec_T'].isnull()) & (astro['spec_B'].isnull())])\n",
    "print(\"There are\",len(astro),\"total observed objects in the dataset\")\n",
    "print((len(astro)-tot_unclassified), \"have been classified, while\",tot_unclassified,\"remain unclassified.\")\n",
    "\n",
    "# Examing distribution of the classified asteroids\n",
    "print(\"---\\nSMASS Value Counts\")\n",
    "print(astro['spec_B'].value_counts())\n",
    "print(\"---\\nTholen Value Counts\")\n",
    "print_all(astro['spec_T'].value_counts())\n",
    "\n",
    "# astro.head()\n",
    "\n",
    "# From this we can see that there are some other M class asteroids in combinded classes,\n",
    "# However, including these only increases the sample from 37 to 41, and includes ambigous\n",
    "# and/or noisy cases, which would not benefit our model\n",
    "\n",
    "\n",
    "# astro['diameter'].describe()\n",
    "# mtype = astro.loc[astro['spec_T'] == \"M\"]\n",
    "# mtype['albedo'].describe()\n",
    "# astro['spec_B'].unique()\n",
    "# uniques = astro['spec_T'].unique()\n",
    "# for x in uniques:\n",
    "#     print(type(x))\n",
    "#     print(x)\n",
    "\n",
    "\n",
    "# metal = astro.loc[(astro['spec_T'].str.contains('M')) | (astro['spec_B'].str.contains('X'))]\n",
    "# metal.shape\n",
    "# metal = astro.loc[(astro['spec_T'] == \"M\") | (astro['spec_B'] == 'X') |\n",
    "#                  (astro['spec_B'] == 'Xc') | (astro['spec_B'] == 'Xe')]\n",
    "# metal.shape\n",
    "\n",
    "# unknowns = astro.loc[(astro['spec_T'].isnull()) & (astro['spec_B'].isnull())]\n",
    "# print(unknowns.shape)\n",
    "\n",
    "# astro['spec_T'].unique()\n",
    "# print(astro.shape)\n",
    "# print(metal.shape)\n",
    "# astro[astro['spec_T'] == 'nan']\n",
    "# print(*astro['spec_T'].value_counts())\n",
    "\n",
    "# astro['n_obs_used'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae99d6e",
   "metadata": {},
   "source": [
    "Now that we have an idea of the distribution, lets subset the metallic identified asteroids, an equal amount of non-metallic asteroids, and use them to build and test a classification model\n",
    "\n",
    "### Note: Revisit later and see if we can just use the entire classified set as the training. Do the metallic and non-metallic need to be equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "81b3767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting metal asteroids and getting an equal amount of classified, nonmetal asteroids\n",
    "classified = astro.loc[(((astro['spec_T'].notnull()) | (astro['spec_B'].notnull())) & astro['albedo'].notnull())]\n",
    "metal = classified.loc[(classified['spec_T'] == \"M\") | (classified['spec_B'] == 'X') | \n",
    "                   (classified['spec_B'] == 'S') | (classified['spec_T'] == 'S')]\n",
    "nonmetal = classified.loc[(classified['spec_T'] != \"M\") & (classified['spec_B'] != 'X') &\n",
    "                 (classified['spec_B'] != 'S') & (classified['spec_T'] != 'S')]\n",
    "\n",
    "# ((astro['spec_T'].notnull()) | (astro['spec_B'].notnull()) & astro['albedo'].notnull())\n",
    "# (astro['spec_T'].notnull()) | (astro['spec_B'].notnull())\n",
    "\n",
    "\n",
    "# Sampling from the nonmetal dataset equally\n",
    "nonmetal_sample = nonmetal.sample(n=(len(metal)))\n",
    "metal.insert(20, \"m_id\", '1')\n",
    "pd.to_numeric(metal[\"m_id\"])\n",
    "nonmetal_sample.insert(20, \"m_id\", '0')\n",
    "pd.to_numeric(nonmetal_sample[\"m_id\"])\n",
    "training_set = pd.concat([metal, nonmetal_sample])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f6460b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[395 147]\n",
      " [ 89 459]]\n",
      "0.7834862385321101\n"
     ]
    }
   ],
   "source": [
    "# X.head()\n",
    "# Creating the model\n",
    "y_var = training_set['m_id'].to_numpy()\n",
    "np.reshape(y_var, (1, -1))\n",
    "X_var = training_set['albedo'].to_numpy()\n",
    "X_var = scale(X_var)\n",
    "\n",
    "## Below this point is not currently working.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_var, y_var, random_state=1, test_size=0.8)\n",
    "\n",
    "x_train = np.reshape(x_train, ((len(x_train), 1)))\n",
    "# y_train = np.reshape(y_train, ((len(y_train), 1)))\n",
    "x_test = np.reshape(x_test, ((len(x_test), 1)))\n",
    "# y_test = np.reshape(y_test, ((len(y_test), 1)))\n",
    "\n",
    "svm_train = svm.SVC(kernel=\"rbf\", C=100, gamma=0.01)\n",
    "svm_train.fit(x_train, y_train)\n",
    "test_pred = svm_train.predict(x_test)\n",
    "print(metrics.confusion_matrix(y_true = y_test, y_pred = test_pred))\n",
    "print(metrics.accuracy_score(y_true = y_test, y_pred = test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
