{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "457094b7",
   "metadata": {},
   "source": [
    "# Classification and Distribution of M-Type Asteroids\n",
    "## Introduction to Data Science (MATH 4100/COMP 5360) Final Project\n",
    "## Matt Storie and Ian Wixom\n",
    "---\n",
    "## Part 0: Setup and Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c147b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and Setup\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6) \n",
    "\n",
    "#Custom Functions for use later\n",
    "#Increases print output for one printing\n",
    "def print_all(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322184f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports are large so I am keeping them in their own cell for now\n",
    "astro1 = pd.read_csv('C:/Users/matts/ds/Classification-and-Analysis-of-M-type-Asteroids/split_astro_ds_1.csv', low_memory = False)\n",
    "astro2 = pd.read_csv('C:/Users/matts/ds/Classification-and-Analysis-of-M-type-Asteroids/split_astro_ds_2.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e7bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frame Formatting\n",
    "# The Second file did not have all of the same columns, so we are adding them now\n",
    "# and filling missing values with NA\n",
    "astro2.columns = ['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'n_obs_used', 'H',\n",
    "       'diameter', 'extent', 'albedo', 'rot_per']\n",
    "astro2['GM'] = np.nan\n",
    "astro2['BV'] = np.nan\n",
    "astro2['UB'] = np.nan\n",
    "astro2['IR'] = np.nan\n",
    "astro2['spec_B'] = np.nan\n",
    "astro2['spec_T'] = np.nan\n",
    "astro = pd.concat([astro1, astro2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a07ca",
   "metadata": {},
   "source": [
    "## Part 1 Classification of Unclassified Asteroids\n",
    "Before we can explore the full set, we are going to need to train a model to classify the unclassified asteroids of the set before exploring the full set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c4c50bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1048573 total observed objects in the dataset\n",
      "1742 have been classified, while 1046831 remain unclassified.\n",
      "---\n",
      "SMASS Value Counts\n",
      "S      348\n",
      "C      139\n",
      "Ch     135\n",
      "X      112\n",
      "Xc      59\n",
      "B       56\n",
      "Sl      47\n",
      "Sq      44\n",
      "Xk      39\n",
      "V       35\n",
      "L       33\n",
      "K       31\n",
      "Cb      30\n",
      "Sa      29\n",
      "Xe      24\n",
      "Cgh     15\n",
      "T       13\n",
      "Sk      12\n",
      "A       12\n",
      "Ld      11\n",
      "Sr      11\n",
      "Cg       9\n",
      "D        8\n",
      "R        4\n",
      "O        1\n",
      "U        1\n",
      "Name: spec_B, dtype: int64\n",
      "---\n",
      "Tholen Value Counts\n",
      "S         311\n",
      "C         137\n",
      "X          51\n",
      "M          37\n",
      "D          33\n",
      "P          33\n",
      "F          27\n",
      "XC         22\n",
      "CX         21\n",
      "C:         10\n",
      "E          10\n",
      "CP         10\n",
      "G           9\n",
      "B           8\n",
      "FC          7\n",
      "SU          7\n",
      "PC          6\n",
      "T           6\n",
      "CU          5\n",
      "CX:         5\n",
      "A           5\n",
      "ST          5\n",
      "XFU         5\n",
      "DU          4\n",
      "CSU         4\n",
      "FXU:        4\n",
      "CG          4\n",
      "CF          4\n",
      "CPF         3\n",
      "DX          3\n",
      "BU          3\n",
      "MU          3\n",
      "GC          3\n",
      "DP          3\n",
      "XD          3\n",
      "CD          3\n",
      "I           3\n",
      "XDC         2\n",
      "XCU         2\n",
      "XD:         2\n",
      "PD          2\n",
      "XF          2\n",
      "FCX         2\n",
      "XB          2\n",
      "CB          2\n",
      "DTU:        2\n",
      "TD          2\n",
      "DT          2\n",
      "DU:         2\n",
      "CD:         2\n",
      "BCU         2\n",
      "CXF         2\n",
      "SR          2\n",
      "TDG         2\n",
      "SCTU        2\n",
      "DCX:        2\n",
      "DCX         2\n",
      "BFC         1\n",
      "BC:         1\n",
      "PDC         1\n",
      "MU:         1\n",
      "FCU         1\n",
      "CGTP:       1\n",
      "XFC         1\n",
      "P:          1\n",
      "XSC         1\n",
      "CFU:        1\n",
      "PF          1\n",
      "FU          1\n",
      "FC:         1\n",
      "CB:         1\n",
      "XU          1\n",
      "AS          1\n",
      "PU          1\n",
      "XSCU        1\n",
      "STU         1\n",
      "G:          1\n",
      "CBU         1\n",
      "FBCU::      1\n",
      "XFCU        1\n",
      "BU:         1\n",
      "DSU:        1\n",
      "CFXU        1\n",
      "SG          1\n",
      "BCU:        1\n",
      "SDU::       1\n",
      "BFX         1\n",
      "DTU         1\n",
      "GS:         1\n",
      "FCB         1\n",
      "XB:         1\n",
      "R           1\n",
      "CSGU        1\n",
      "F:          1\n",
      "X:          1\n",
      "FP          1\n",
      "BFU::       1\n",
      "CGU         1\n",
      "CDX:        1\n",
      "CFB:        1\n",
      "XC:         1\n",
      "PCD         1\n",
      "TSD         1\n",
      "FCX:        1\n",
      "SD          1\n",
      "CTGU:       1\n",
      "GU          1\n",
      "CP:         1\n",
      "DX:         1\n",
      "STGD        1\n",
      "CGSU        1\n",
      "FX:         1\n",
      "SC          1\n",
      "CPU:        1\n",
      "GC:         1\n",
      "DXCU        1\n",
      "V           1\n",
      "QSV         1\n",
      "CBU:        1\n",
      "TS          1\n",
      "Name: spec_T, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Now that the frames are combined we can perform exploratory analysis\n",
    "# print(astro.head())\n",
    "\n",
    "# Examining the number of unclassified asteroids of the dataset\n",
    "tot_unclassified = len(astro[(astro['spec_T'].isnull()) & (astro['spec_B'].isnull())])\n",
    "print(\"There are\",len(astro),\"total observed objects in the dataset\")\n",
    "print((len(astro)-tot_unclassified), \"have been classified, while\",tot_unclassified,\"remain unclassified.\")\n",
    "\n",
    "# Examing distribution of the classified asteroids\n",
    "print(\"---\\nSMASS Value Counts\")\n",
    "print(astro['spec_B'].value_counts())\n",
    "print(\"---\\nTholen Value Counts\")\n",
    "print_all(astro['spec_T'].value_counts())\n",
    "\n",
    "# From this we can see that there are some other M class asteroids in combinded classes,\n",
    "# However, including these only increases the sample from 37 to 41, and includes ambigous\n",
    "# and/or noisy cases, which would not benefit our model\n",
    "\n",
    "\n",
    "# astro['diameter'].describe()\n",
    "# mtype = astro.loc[astro['spec_T'] == \"M\"]\n",
    "# mtype['albedo'].describe()\n",
    "# astro['spec_B'].unique()\n",
    "# uniques = astro['spec_T'].unique()\n",
    "# for x in uniques:\n",
    "#     print(type(x))\n",
    "#     print(x)\n",
    "\n",
    "\n",
    "# metal = astro.loc[(astro['spec_T'].str.contains('M')) | (astro['spec_B'].str.contains('X'))]\n",
    "# metal.shape\n",
    "# metal = astro.loc[(astro['spec_T'] == \"M\") | (astro['spec_B'] == 'X') |\n",
    "#                  (astro['spec_B'] == 'Xc') | (astro['spec_B'] == 'Xe')]\n",
    "# metal.shape\n",
    "\n",
    "# unknowns = astro.loc[(astro['spec_T'].isnull()) & (astro['spec_B'].isnull())]\n",
    "# print(unknowns.shape)\n",
    "\n",
    "# astro['spec_T'].unique()\n",
    "# print(astro.shape)\n",
    "# print(metal.shape)\n",
    "# astro[astro['spec_T'] == 'nan']\n",
    "# print(*astro['spec_T'].value_counts())\n",
    "\n",
    "# astro['n_obs_used'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae99d6e",
   "metadata": {},
   "source": [
    "Now that we have an idea of the distribution, lets subset the metallic identified asteroids, an equal amount of non-metallic asteroids, and use them to build and test a classification model\n",
    "\n",
    "### Note: Revisit later and see if we can just use the entire classified set as the training. Do the metallic and non-metallic need to be equal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81b3767b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(<bound method IndexOpsMixin.to_numpy of 15      0.1203\n20      0.2212\n21      0.1660\n43      0.4820\n45      0.0460\n         ...  \n49      0.0500\n3397    0.3000\n3007    0.0440\n2645    0.1620\n4968    0.3880\nName: albedo, Length: 434, dtype: float64>, dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2540\\174998400.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'albedo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0msvm_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rbf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0msvm_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2415\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2417\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \"\"\"\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \"\"\"\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    267\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             raise TypeError(\n\u001b[0m\u001b[0;32m    270\u001b[0m                 \u001b[1;34m\"Singleton array %r cannot be considered a valid collection.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m             )\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(<bound method IndexOpsMixin.to_numpy of 15      0.1203\n20      0.2212\n21      0.1660\n43      0.4820\n45      0.0460\n         ...  \n49      0.0500\n3397    0.3000\n3007    0.0440\n2645    0.1620\n4968    0.3880\nName: albedo, Length: 434, dtype: float64>, dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "# Subsetting metal asteroids and getting an equal amount of classified, nonmetal asteroids\n",
    "classified = astro.loc[(astro['spec_T'].notnull()) | (astro['spec_B'].notnull())]\n",
    "metal = classified.loc[(classified['spec_T'] == \"M\") | (classified['spec_B'] == 'X') | \n",
    "                   (classified['spec_B'] == 'Xc') | (classified['spec_B'] == 'Xe')]\n",
    "nonmetal = classified.loc[(classified['spec_T'] != \"M\") & (classified['spec_B'] != 'X') &\n",
    "                 (classified['spec_B'] != 'Xc') & (classified['spec_B'] != 'Xe') & classified['spec_B']]\n",
    "\n",
    "# Sampling from the nonmetal dataset equally\n",
    "nonmetal_sample = nonmetal.sample(n=(len(metal)))\n",
    "metal.insert(20, \"m_id\", '1')\n",
    "pd.to_numeric(metal[\"m_id\"])\n",
    "nonmetal_sample.insert(20, \"m_id\", '0')\n",
    "pd.to_numeric(nonmetal_sample[\"m_id\"])\n",
    "training_set = pd.concat([metal, nonmetal_sample])\n",
    "\n",
    "# X.head()\n",
    "# Creating the model\n",
    "y = training_set['m_id']\n",
    "X = training_set['albedo'].to_numpy\n",
    "\n",
    "## Below this point is not currently working.\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.8)\n",
    "svm_train = svm.SVC(kernel=\"rbf\", C=100, gamma=0.01)\n",
    "svm_train.fit(x_train, y_train)\n",
    "test_pred =svm_train.predict(x_test)\n",
    "print(metrics.confusion_matrix(y_true = y_test, y_pred = test_pred))\n",
    "print(metrics.accuracy_score(y_true = y_test, y_pred = test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
